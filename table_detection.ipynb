{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from sklearn.cluster import KMeans\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regulation Table Tennis dimensions in cm\n",
    "TBL_WIDTH = 152.5\n",
    "TBL_LENGTH = 274\n",
    "TBL_ASPECT_RATIO = TBL_WIDTH/TBL_LENGTH\n",
    "# For these two pairs refer to the following lines 0: Bottom Right, 1: Top Left, 2: Top Right, 3: Bottom Left\n",
    "LINE_PAIRS = [[0, 3], [3, 1], [1, 2], [2, 0]] # Botttom, Left, Top, Right\n",
    "TABLE_COORDS = np.array([[TBL_WIDTH, TBL_LENGTH], [0, TBL_LENGTH], [0, 0], [TBL_WIDTH, 0]], np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_table_size = 8_000\n",
    "img_sz = (960, 540)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers(data, m = 5):\n",
    "    d = np.abs(data - np.median(data))\n",
    "    mdev = np.median(d)\n",
    "    s = d/mdev if mdev else 0.\n",
    "    outliers = np.array([False if x < m else True for x in s])\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equation of the tangent line at $(x_0, y_0)$ to the circle with radius $\\rho$ and center at the origin is: $xx_0+yy_0=\\rho^2$ where $(x_0, y_0)=(\\rho\\cos\\theta, \\rho\\sin\\theta)$\\\n",
    "This gives the equation: $x\\cos\\theta+y\\sin\\theta=\\rho$\\\n",
    "In cartesian form: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_intersections(lines):\n",
    "    # Sort lines by theta so the lines are split into pairs of parallel lines\n",
    "    lines = lines[lines[:, 1].argsort()]\n",
    "    pts = []\n",
    "    for i in range(len(LINE_PAIRS)):\n",
    "        line_0, line_1 = lines[LINE_PAIRS[i]]\n",
    "        rho_0, theta_0 = line_0\n",
    "        rho_1, theta_1 = line_1\n",
    "        b_0 = rho_0/math.sin(theta_0)\n",
    "        b_1 = rho_1/math.sin(theta_1)\n",
    "        m_0 = -math.tan(theta_0)**-1\n",
    "        m_1 = -math.tan(theta_1)**-1\n",
    "        x = (b_1-b_0)/(m_0-m_1)\n",
    "        y = (b_1*m_0 - b_0*m_1)/(m_0-m_1)\n",
    "        pts.append([x, y])\n",
    "    pts = np.array(pts, np.float32)\n",
    "    return pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handleMouseClick(event, x, y, flags, param):\n",
    "    # if event == cv.EVENT_LBUTTONUP:\n",
    "    t_pts = cv.transform(np.array([[x, y]], np.float32).reshape((-1, 1, 2)), param[\"t\"])\n",
    "    t_pts = t_pts.reshape((1, 3))\n",
    "    t_pts = t_pts[:,:2] / t_pts[:, -1].reshape(-1, 1) # Normalize using third column\n",
    "    t_pts = t_pts.astype(np.int32)[0] # Convert from float to int, and flit to match Numpy convention\n",
    "    frame = np.zeros((274, 153)) # y, x\n",
    "    frame[137] = np.ones((1, 153))*255\n",
    "    frame[:, 77] = np.ones((274, 1)).ravel()*255\n",
    "    frame = cv.circle(frame, t_pts, 5, (255, 255, 255), -1)\n",
    "    cv.imshow(\"Location\", frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Hough Lines and the table dimensions to determine the corner positions\n",
    "def find_corners(lines, areas, frame):\n",
    "    outliers = find_outliers(areas)\n",
    "    lines = lines[np.invert(outliers)]\n",
    "    lines = np.array(list(chain.from_iterable(lines)))\n",
    "    kmeans = KMeans(n_clusters=4, random_state=0).fit(lines)\n",
    "    pts = find_intersections(kmeans.cluster_centers_)\n",
    "    tform = cv.getPerspectiveTransform(pts, TABLE_COORDS, cv.DECOMP_LU)\n",
    "    # t_pts = cv.transform(pts.reshape((-1, 1, 2)), tform)\n",
    "    # t_pts = t_pts.reshape((4, 3))\n",
    "    # t_pts = t_pts[:,:2] / t_pts[:, -1].reshape(-1, 1) # Normalize using third column\n",
    "    corners = pts.astype(np.int32)\n",
    "    corners = np.reshape(corners, (-1,1,2))\n",
    "    overlay = frame.copy()\n",
    "    cv.fillPoly(overlay,[corners],(0,255,255))\n",
    "    overlay = cv.addWeighted(overlay, 0.5, frame, 0.5, 0)\n",
    "    cv.imshow(\"frame\", overlay)\n",
    "    cv.setMouseCallback('frame', lambda event, x, y, flags, param: handleMouseClick(event, x, y, flags, param={\"t\": tform}))\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()\n",
    "    cv.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_segmentation(input_video_path):\n",
    "    table_color_lower = (107, 0, 0)\n",
    "    table_color_upper = (120, 255, 255)\n",
    "    capture = cv.VideoCapture(input_video_path)\n",
    "    num_frames = int(capture.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "    resize_factor = 10\n",
    "    n_samples = 7\n",
    "    table_areas = []\n",
    "    table_lines = []\n",
    "    # Randomly sample n_samples frames from the video to get the best chance of finding frames of unobstructed table\n",
    "    # Save the contour area values to identify outliers, only use nonn-outlier values to find table lines\n",
    "    random_frames = random.sample(range(num_frames), n_samples)\n",
    "    for i in random_frames:\n",
    "        capture.set(cv.CAP_PROP_POS_FRAMES, i)\n",
    "        ret, frame = capture.read()\n",
    "        if frame is None:\n",
    "            break\n",
    "        # Normalize image size\n",
    "        frame = cv.resize(frame, img_sz)\n",
    "        blurred = cv.GaussianBlur(frame, (3, 3), 0)\n",
    "        hsv = cv.cvtColor(blurred, cv.COLOR_BGR2HSV)\n",
    "        mask = cv.inRange(hsv, table_color_lower, table_color_upper)\n",
    "        kernel = np.ones((4, 4), np.uint8)\n",
    "        mask = cv.morphologyEx(mask, cv.MORPH_OPEN, kernel)\n",
    "        mask = cv.morphologyEx(mask, cv.MORPH_CLOSE, kernel)\n",
    "        contours, _ = cv.findContours(mask, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "        contours = list(contours)\n",
    "        # filter out contours that are too small\n",
    "        # filter out contours that are too big\n",
    "        # find the contour with the closest center to the center of the frame\n",
    "        table_cnt = None\n",
    "        min_center_dist = (img_sz[0]**2 + img_sz[1]**2)**0.5 # initialize to largest possible value (corner of frame,furthest from center)\n",
    "        frame_center = tuple([dim/2 for dim in img_sz])\n",
    "        for cnt in contours:\n",
    "            if cv.contourArea(cnt) > min_table_size:\n",
    "                moments = cv.moments(cnt)\n",
    "                cX = int(moments[\"m10\"] / moments[\"m00\"])\n",
    "                cY = int(moments[\"m01\"] / moments[\"m00\"])\n",
    "                euclid_dst = ((frame_center[0] - cX)**2 + (frame_center[1] - cY)**2)**0.5\n",
    "                if euclid_dst < min_center_dist:\n",
    "                    min_center_dist = euclid_dst\n",
    "                    table_cnt = cnt\n",
    "        # Use thin contour border crucial to increasing accuracy of the angle of the lines created\n",
    "        cnt_img = cv.drawContours(np.zeros((mask.shape[0],mask.shape[1]), np.uint8), [table_cnt], 0, (255, 255, 255), 1)\n",
    "        # rho: specifies how straight the line has to be, lower => stricter\n",
    "        # theta: specifies how similar the lines need to be to be considered the same line, higher => combines more lines\n",
    "        # threshold: specifies how many points leed to lie on the line to be considered a line, higher => stricter\n",
    "        lines = cv.HoughLines(cnt_img, 1, 2*np.pi / 180, 50, None, 0, 0)\n",
    "        lines = lines.reshape((-1, 2))\n",
    "        table_areas.append(cv.contourArea(table_cnt))\n",
    "        table_lines.append(lines)\n",
    "        keyboard = cv.waitKey(30)\n",
    "        if keyboard == 'q' or keyboard == 27:\n",
    "            break\n",
    "    table_lines = np.array(table_lines)\n",
    "    find_corners(table_lines, table_areas, frame)\n",
    "    capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s3/v3l8xgqd3xdgc1ll_pmdv1qr0000gn/T/ipykernel_87374/855033017.py:55: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  table_lines = np.array(table_lines)\n",
      "2022-12-18 18:22:05.380 Python[87374:2466984] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to /var/folders/s3/v3l8xgqd3xdgc1ll_pmdv1qr0000gn/T/org.python.python.savedState\n"
     ]
    }
   ],
   "source": [
    "for video_num in range(0, 10):\n",
    "    input_video_path = f\"./imp/videos/videos_0/{video_num}.mov\"\n",
    "    image_segmentation(input_video_path)\n",
    "cv.destroyAllWindows()\n",
    "cv.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('tt_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "524fc15747148b2532d87f584d1b6e471ef51f3fa0e892e230957e0ba9637d40"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
